{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The weights for our embeddings are initialized from running word2vec on our corpus \n",
    "# using gensim package. Attention is modeled as a dot product of the output of the \n",
    "# question and answer vectors that come out of the LSTMs. Finally, the attention \n",
    "# vector and question vectors are concatenated (mode='sum') and sent into a Dense network, \n",
    "# which outputs the probabilities for True/False and are further converted back into the characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Dropout, Reshape, Flatten, merge\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Model\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import re\n",
    "import collections\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_embed_size = 100\n",
    "qa_embed_size = 64\n",
    "batch_size = 128\n",
    "nbr_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tid\tquestion\tcorrectAnswer\tanswerA\tanswerB\tanswerC\tanswerD\r\n",
      "\n",
      "0\t100001\t\"When athletes begin to exercise, their heart rates and respiration rates increase.  At what level of organization does the human body coordinate these functions?\"\tC\tat the tissue level\tat the organ level\tat the system level\tat the cellular level\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('/home/ramscrux7757/SPARK/AI_SCIENCE/train.txt', \"r\") as f:\n",
    "    print f.readline()\n",
    "    print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# processing questions and answers in training set\n",
    "# This produces a list of lists (question - words, answers - words and the boolean for correct answer)\n",
    "\n",
    "qapairs = []\n",
    "with open('/home/ramscrux7757/SPARK/AI_SCIENCE/train.txt') as train_qa:\n",
    "    next(train_qa)\n",
    "    for line in train_qa:\n",
    "        line = line.strip().decode('utf8').encode('ascii','ignore')\n",
    "        cols = line.split('\\t')\n",
    "        question = cols[2]\n",
    "        tokens = nltk.word_tokenize(question)\n",
    "    # filter alphanumerics\n",
    "        words = [word for word in tokens if word.isalpha()]\n",
    "    # filter stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        qwords = [W for W in words if not W in stop_words]\n",
    "    # normalize cases\n",
    "        qwords = [word.lower() for word in qwords]\n",
    "    # Stemming of Words\n",
    "        porter = PorterStemmer()\n",
    "        qwords = [porter.stem(word) for word in qwords]\n",
    "        qwords = [s.encode('UTF-8', 'strict') for s in qwords]\n",
    "        \n",
    "    # filter correct answers\n",
    "        correct_ans = cols[3]\n",
    "    # filter all the answers\n",
    "        answers = cols[4:]\n",
    "    # training file parsing\n",
    "        correct_ans_idx = ord(correct_ans) - ord('A') # 'ord' - converts character to integer\n",
    "        for idx,answer in enumerate(answers):\n",
    "            tokens2 = nltk.word_tokenize(answer)                 # tokenization\n",
    "            words = [word for word in tokens2 if word.isalpha()] # alphanumeric\n",
    "            stop_words2 = set(stopwords.words('english'))        # stopwords\n",
    "            awords = [W for W in words if not W in stop_words2]\n",
    "            awords = [word.lower() for word in awords]           # normalization\n",
    "            awords = [porter.stem(word) for word in awords]      # stemming\n",
    "            awords = [s.encode('UTF-8', 'strict') for s in awords] # unicode to UTF-8\n",
    "        \n",
    "            qapairs.append((qwords,awords, idx == correct_ans_idx)) # (idx == correct_ans_idx -- returns a boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['when', 'athlet', 'begin', 'exercis', 'heart', 'rate', 'respir', 'rate', 'increas', 'at', 'level', 'organ', 'human', 'bodi', 'coordin', 'function'], ['system', 'level'], True)\n",
      "['when', 'athlet', 'begin', 'exercis', 'heart', 'rate', 'respir', 'rate', 'increas', 'at', 'level', 'organ', 'human', 'bodi', 'coordin', 'function']\n",
      "['tissu', 'level']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(qapairs[2])\n",
    "print(qapairs[0][0]) # 1st questions\n",
    "print(qapairs[0][1]) # option 'A' for first question - each question carries 3 options\n",
    "print(qapairs[2][2]) # Determines whether its the right answer or not (boolean) - indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for qapair in qapairs:\n",
    "#    print(qapair[0]) # question\n",
    "#    print(qapair[1]) # choice of answers\n",
    "#    print(qapair[2]) # index as boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# processing the test set\n",
    "\n",
    "tqapairs = []\n",
    "with open('/home/ramscrux7757/SPARK/AI_SCIENCE/test.txt') as test_qa:\n",
    "    next(test_qa)\n",
    "    \n",
    "    for line in test_qa:\n",
    "        line = line.strip().decode('utf8').encode('ascii','ignore')\n",
    "        cols = line.split('\\t')\n",
    "        question = cols[2]\n",
    "        tokens = nltk.word_tokenize(question)\n",
    "    # filter alphanumeric\n",
    "        words = [word for word in tokens if word.isalpha()]\n",
    "    # filter stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tqwords = [W for W in words if not W in stop_words]\n",
    "    # normalize cases\n",
    "        tqwords = [word.lower() for word in tqwords]\n",
    "    # Stemming of Words\n",
    "        porter = PorterStemmer()\n",
    "        tqwords = [porter.stem(word) for word in tqwords]\n",
    "        tqwords = [s.encode('UTF-8', 'strict') for s in tqwords]\n",
    "    \n",
    "    #filter answers\n",
    "        answers = cols[3:]\n",
    "\n",
    "        for answer in answers:\n",
    "            tokens2 = nltk.word_tokenize(answer)\n",
    "            words = [word for word in tokens2 if word.isalpha()]\n",
    "            stop_words2 = set(stopwords.words('english'))\n",
    "            tawords = [W for W in words if not W in stop_words2]\n",
    "            tawords = [word.lower() for word in tawords]\n",
    "            tawords = [porter.stem(word) for word in tawords]\n",
    "            tawords = [s.encode('UTF-8', 'strict') for s in tawords]\n",
    "        \n",
    "            tqapairs.append((tqwords,tawords, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['a', 'meter', 'industri', 'develop', 'process', 'heat', 'cool', 'exampl', 'bodi', 'system'], ['cool', 'food', 'ship'], None)\n"
     ]
    }
   ],
   "source": [
    "print(tqapairs[0])\n",
    "#print(qapairs[0][0]) # 1st questions\n",
    "#print(qapairs[0][1]) # option 'A' for first question - each question carries 3 options\n",
    "#print(qapairs[2][2]) # Determines whether its the right answer or not (boolean) - indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "15\n",
      "81\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# Dimensions for questions and answers\n",
    "tr_qns_maxlen = max([len(qapair[0]) for qapair in qapairs])\n",
    "tr_ans_maxlen = max([len(qapair[1]) for qapair in qapairs])\n",
    "\n",
    "tst_qns_maxlen = max([len(qapair[0]) for qapair in tqapairs])\n",
    "tst_ans_maxlen = max([len(qapair[1]) for qapair in tqapairs])\n",
    "\n",
    "print(tr_qns_maxlen)\n",
    "print(tr_ans_maxlen)\n",
    "print(tst_qns_maxlen)\n",
    "print(tst_ans_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Determining the length of the word vectors\n",
    "seq_maxlen = max([tr_qns_maxlen, tr_ans_maxlen, tst_qns_maxlen, tst_ans_maxlen])\n",
    "print(seq_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a dictionary of words with indexes - \n",
    "# starts with the word count and collects the unique words \n",
    "# and iterates/enumerate (indexes) them\n",
    "\n",
    "def build_vocab(qapairs, testqs):\n",
    "    wordcounts = collections.Counter()\n",
    "    for qapair in qapairs:\n",
    "        for qword in qapair[0]:\n",
    "            wordcounts[qword] += 1\n",
    "        for aword in qapair[1]:\n",
    "            wordcounts[aword] += 1\n",
    "    for testq in testqs:\n",
    "        for qword in testq[0]:\n",
    "            wordcounts[qword] += 1\n",
    "        for aword in testq[1]:\n",
    "            wordcounts[aword] += 1\n",
    "    words = [wordcount[0] for wordcount in wordcounts.most_common()]\n",
    "    word2idx = {w: i+1 for i, w in enumerate(words)}  # 0 = mask\n",
    "    return word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each word along with its index in the vocabulary space\n",
    "\n",
    "word2idx = build_vocab(qapairs,tqapairs)\n",
    "vocab_size = len(word2idx) + 1\n",
    "#print(vocab_size)\n",
    "#print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5735\n",
      "['xylem', 'woodi', 'yellow', 'interchang', 'four', 'prefix', 'authorit', 'accret', 'chlorophyl', 'pigment']\n"
     ]
    }
   ],
   "source": [
    "vocab = []\n",
    "for key in word2idx.keys():\n",
    "  vocab.append(key)\n",
    "\n",
    "print(len(vocab))\n",
    "print(vocab[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# based on the vocabulary space created above, the corresponding \n",
    "# questions and answers lists (in qapairs) are re-represented by the corresponding\n",
    "# numeric index followed by the padding (add's '0's starting from location '0') \n",
    "# to match to the seq_maxlen\n",
    "\n",
    "def vectorize_qapairs(qapairs, word2idx, seq_maxlen):\n",
    "    Xq, Xa, Y = [], [], []\n",
    "    for qapair in qapairs:\n",
    "        Xq.append([word2idx[qword] for qword in qapair[0]])\n",
    "        Xa.append([word2idx[aword] for aword in qapair[1]])\n",
    "        Y.append(np.array([1, 0]) if qapair[2] else np.array([0, 1]))\n",
    "    return (pad_sequences(Xq, maxlen=seq_maxlen), \n",
    "            pad_sequences(Xa, maxlen=seq_maxlen),\n",
    "            np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...,   17 2676   45]\n",
      " [   0    0    0 ...,   17 2676   45]\n",
      " [   0    0    0 ...,   17 2676   45]\n",
      " ..., \n",
      " [   0    0    0 ...,  527   46  187]\n",
      " [   0    0    0 ...,  527   46  187]\n",
      " [   0    0    0 ...,  527   46  187]]\n",
      "[[   0    0    0 ...,    0  287  196]\n",
      " [   0    0    0 ...,    0    6  196]\n",
      " [   0    0    0 ...,    0   16  196]\n",
      " ..., \n",
      " [   0    0    0 ...,   10 1392 5628]\n",
      " [   0    0    0 ...,   49  329 1915]\n",
      " [   0    0    0 ...,  527 1093 2226]]\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " ..., \n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "# index encoded qapairs vectors\n",
    "Xq, Xa, Y = vectorize_qapairs(qapairs, word2idx, seq_maxlen)\n",
    "print(Xq)\n",
    "print(Xa)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generating wordembeddings using gensim package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# converts the lists of list to a flat list\n",
    "# flat_list = [item for sublist in vocab2 for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=5735, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "# Generating embedding model using gensim\n",
    "\n",
    "# train model \n",
    "ebd_model = Word2Vec([vocab], min_count = 1)\n",
    "# summrize the moaded model\n",
    "print(ebd_model)\n",
    "\n",
    "# summarize vocabulary\n",
    "#words = list(model.wv.vocab)\n",
    "#print(words)\n",
    "\n",
    "# access for vector for one word\n",
    "#print(model['athletes'])\n",
    "\n",
    "# save model\n",
    "ebd_model.save('/home/ramscrux7757/SPARK/AI_SCIENCE/ebd_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.91042659e-03   2.49395682e-03  -4.18240158e-03  -1.65743125e-03\n",
      "   2.89677293e-03   3.02499766e-03   3.10987374e-03  -4.59121354e-03\n",
      "  -4.70060902e-03   2.91275466e-03   4.78292909e-03   1.27905584e-03\n",
      "  -3.00291926e-03  -4.02065134e-03  -3.25951097e-03   3.14298226e-03\n",
      "   1.62889529e-03   1.79575360e-03   1.64707063e-03   1.73439912e-03\n",
      "   4.04637493e-03   4.82955336e-04   1.85453310e-03  -1.81779847e-03\n",
      "  -4.94532927e-04  -2.54604011e-03   1.70876936e-03   9.12451418e-04\n",
      "   3.66605585e-04   3.56892636e-03  -1.11761491e-03   2.51542078e-03\n",
      "  -4.03980631e-03   2.33085686e-03  -2.62790173e-03   4.96898172e-03\n",
      "  -2.08235905e-03   4.48652869e-03   4.22187103e-03  -6.51758397e-04\n",
      "  -2.23297207e-03  -3.53306183e-03  -7.13144036e-05  -4.31352155e-03\n",
      "   8.81786866e-04   4.99189971e-03  -3.22834821e-03  -2.41151266e-03\n",
      "   5.16865926e-04   3.69538204e-03  -1.44541077e-03   1.32763362e-03\n",
      "   3.41612939e-03   1.18610007e-03   4.18455293e-03  -8.07214994e-04\n",
      "   3.03713558e-03   1.56300061e-03  -1.14547182e-03   2.75444565e-03\n",
      "  -8.04641750e-04   3.72998347e-03   1.60866173e-03  -2.00418886e-04\n",
      "  -3.45045282e-03  -8.68252886e-04   4.58775507e-03   4.42421064e-03\n",
      "   3.92366783e-04  -4.21363674e-03   3.93568352e-03  -3.34461220e-03\n",
      "  -4.83735232e-03   2.00627046e-03   1.08981866e-03  -4.18146094e-03\n",
      "   1.86865416e-03  -3.29733687e-03   2.38885565e-04  -4.59920702e-05\n",
      "   3.56721313e-04   2.55280465e-04  -2.59637856e-03   3.99745069e-03\n",
      "  -1.05514354e-03  -1.75907440e-03  -1.12220761e-03  -8.57748208e-04\n",
      "  -3.00825061e-03   3.74237471e-03  -3.14180832e-03  -2.36984815e-05\n",
      "  -3.46772070e-03   8.76652426e-04  -3.85535671e-03  -1.49304059e-03\n",
      "   4.93653025e-03  -1.51491887e-03   6.56708260e-04  -4.73161973e-03]\n"
     ]
    }
   ],
   "source": [
    "print(ebd_model['xylem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this converts the word based embedding vector representations (shown above)\n",
    "# to index based (as per the vocabulary indexes)\n",
    "\n",
    "w2v_embed_size = 100\n",
    "vocab_size = len(word2idx) + 1\n",
    "embedding_weights = np.zeros((vocab_size, w2v_embed_size))\n",
    "for word, index in word2idx.items():\n",
    "    embedding_weights[index, :] = ebd_model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.91042659e-03,   2.49395682e-03,  -4.18240158e-03,\n",
       "        -1.65743125e-03,   2.89677293e-03,   3.02499766e-03,\n",
       "         3.10987374e-03,  -4.59121354e-03,  -4.70060902e-03,\n",
       "         2.91275466e-03,   4.78292909e-03,   1.27905584e-03,\n",
       "        -3.00291926e-03,  -4.02065134e-03,  -3.25951097e-03,\n",
       "         3.14298226e-03,   1.62889529e-03,   1.79575360e-03,\n",
       "         1.64707063e-03,   1.73439912e-03,   4.04637493e-03,\n",
       "         4.82955336e-04,   1.85453310e-03,  -1.81779847e-03,\n",
       "        -4.94532927e-04,  -2.54604011e-03,   1.70876936e-03,\n",
       "         9.12451418e-04,   3.66605585e-04,   3.56892636e-03,\n",
       "        -1.11761491e-03,   2.51542078e-03,  -4.03980631e-03,\n",
       "         2.33085686e-03,  -2.62790173e-03,   4.96898172e-03,\n",
       "        -2.08235905e-03,   4.48652869e-03,   4.22187103e-03,\n",
       "        -6.51758397e-04,  -2.23297207e-03,  -3.53306183e-03,\n",
       "        -7.13144036e-05,  -4.31352155e-03,   8.81786866e-04,\n",
       "         4.99189971e-03,  -3.22834821e-03,  -2.41151266e-03,\n",
       "         5.16865926e-04,   3.69538204e-03,  -1.44541077e-03,\n",
       "         1.32763362e-03,   3.41612939e-03,   1.18610007e-03,\n",
       "         4.18455293e-03,  -8.07214994e-04,   3.03713558e-03,\n",
       "         1.56300061e-03,  -1.14547182e-03,   2.75444565e-03,\n",
       "        -8.04641750e-04,   3.72998347e-03,   1.60866173e-03,\n",
       "        -2.00418886e-04,  -3.45045282e-03,  -8.68252886e-04,\n",
       "         4.58775507e-03,   4.42421064e-03,   3.92366783e-04,\n",
       "        -4.21363674e-03,   3.93568352e-03,  -3.34461220e-03,\n",
       "        -4.83735232e-03,   2.00627046e-03,   1.08981866e-03,\n",
       "        -4.18146094e-03,   1.86865416e-03,  -3.29733687e-03,\n",
       "         2.38885565e-04,  -4.59920702e-05,   3.56721313e-04,\n",
       "         2.55280465e-04,  -2.59637856e-03,   3.99745069e-03,\n",
       "        -1.05514354e-03,  -1.75907440e-03,  -1.12220761e-03,\n",
       "        -8.57748208e-04,  -3.00825061e-03,   3.74237471e-03,\n",
       "        -3.14180832e-03,  -2.36984815e-05,  -3.46772070e-03,\n",
       "         8.76652426e-04,  -3.85535671e-03,  -1.49304059e-03,\n",
       "         4.93653025e-03,  -1.51491887e-03,   6.56708260e-04,\n",
       "        -4.73161973e-03])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_weights[1558] # xylem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if we want to load the embedding model\n",
    "#word2vec = Word2Vec.load('/home/ramscrux7757/SPARK/AI_SCIENCE/ebd_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualizing wordembeddings\n",
    "X = ebd_model[ebd_model.wv.vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njIlgicEYY0wESwzGGGMiWGIwxhgT4f8DYdsYVenLKEAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f954a8621d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot word vectors using PCA\n",
    "from matplotlib import pyplot\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 2)\n",
    "result = pca.fit_transform(X)\n",
    "# create a scatter plot\n",
    "pyplot.scatter(result[:,0],result[:,1])\n",
    "words = list(ebd_model.wv.vocab)\n",
    "for i, word in enumerate(words):\n",
    "    pyplot.annotate(word, xy=(result[i,0], result[i,1]))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if we want to use google word2vec\n",
    "#from gensim.models import Word2Vec\n",
    "#word2vec = KeyedVectors.load_word2vec_format('/home/ramscrux7757/SPARK/AI_SCIENCE/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling part (LSTM w/ Attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((7000, 100), (3000, 100), (7000, 100), (3000, 100), (7000, 2), (3000, 2))\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data\n",
    "Xqtrain, Xqtest, Xatrain,Xatest,Ytrain,Ytest = train_test_split(Xq,Xa,Y,test_size=0.3,random_state=123)\n",
    "print(Xqtrain.shape, Xqtest.shape,Xatrain.shape,Xatest.shape,Ytrain.shape,Ytest.shape)\n",
    "\n",
    "# Y - is a True/False matrix w.r.to 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network for questions\n",
    "qin = Input(shape=(seq_maxlen,), dtype=\"int32\") # seq_maxlen = 100\n",
    "# vocab_size = 5736; WORD2VEC_EMBED_SIZE = 100\n",
    "\n",
    "qenc = Embedding(input_dim=vocab_size,\n",
    "                 output_dim=word2vec_embed_size,\n",
    "                 input_length=seq_maxlen,\n",
    "                 weights=[embedding_weights])(qin)\n",
    "\n",
    "# QA_EMBED_SIZE = 64\n",
    "qenc = LSTM(qa_embed_size, return_sequences=True)(qenc)\n",
    "qenc = Dropout(0.3)(qenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network for answers\n",
    "# output: (None, QA_EMBED_SIZE, seq_maxlen)\n",
    "ain = Input(shape=(seq_maxlen,), dtype=\"int32\")\n",
    "aenc = Embedding(input_dim=vocab_size,\n",
    "                 output_dim= word2vec_embed_size,\n",
    "                 input_length=seq_maxlen,\n",
    "                 weights=[embedding_weights])(ain)\n",
    "aenc = LSTM(qa_embed_size, return_sequences=True)(aenc)\n",
    "aenc = Dropout(0.3)(aenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 100, 100)      573600      input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)          (None, 100, 100)      573600      input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 100, 64)       42240       embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 100, 64)       42240       embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 100, 64)       0           lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 100, 64)       0           lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 64, 64)        0           dropout_1[0][0]                  \n",
      "                                                                   dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 4096)          0           merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 6400)          26220800    flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)              (None, 100, 64)       0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                  (None, 100, 64)       0           dropout_1[0][0]                  \n",
      "                                                                   reshape_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 6400)          0           merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 2)             12802       flatten_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 27,465,282\n",
      "Trainable params: 27,465,282\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/anaconda/lib/python2.7/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/usr/local/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:8: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/usr/local/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:13: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "# attention model (dot product)\n",
    "attn = merge([qenc, aenc], mode=\"dot\", dot_axes=[1, 1])\n",
    "attn = Flatten()(attn)\n",
    "attn = Dense(seq_maxlen * qa_embed_size)(attn)\n",
    "attn = Reshape((seq_maxlen, qa_embed_size))(attn)\n",
    "\n",
    "# merging using 'sum'\n",
    "qenc_attn = merge([qenc, attn], mode=\"sum\")\n",
    "qenc_attn = Flatten()(qenc_attn)\n",
    "\n",
    "output = Dense(2, activation=\"softmax\")(qenc_attn)\n",
    "\n",
    "model = Model(input=[qin, ain], output=[output])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:7: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/10\n",
      "6272/6300 [============================>.] - ETA: 0s - loss: 0.5711 - acc: 0.7433Epoch 00000: val_loss improved from inf to 0.57969, saving model to /home/ramscrux7757/SPARK/AI_SCIENCE/qa-lstm-attn-best.hdf5\n",
      "6300/6300 [==============================] - 89s - loss: 0.5712 - acc: 0.7432 - val_loss: 0.5797 - val_acc: 0.7343\n",
      "Epoch 2/10\n",
      "6272/6300 [============================>.] - ETA: 0s - loss: 0.5625 - acc: 0.7503Epoch 00001: val_loss did not improve\n",
      "6300/6300 [==============================] - 84s - loss: 0.5631 - acc: 0.7498 - val_loss: 0.5804 - val_acc: 0.7343\n",
      "Epoch 3/10\n",
      "6272/6300 [============================>.] - ETA: 0s - loss: 0.5580 - acc: 0.7511Epoch 00002: val_loss did not improve\n",
      "6300/6300 [==============================] - 85s - loss: 0.5589 - acc: 0.7498 - val_loss: 0.6496 - val_acc: 0.6443\n",
      "Epoch 4/10\n",
      "6272/6300 [============================>.] - ETA: 0s - loss: 0.5060 - acc: 0.7661Epoch 00003: val_loss did not improve\n",
      "6300/6300 [==============================] - 81s - loss: 0.5064 - acc: 0.7659 - val_loss: 0.6726 - val_acc: 0.7214\n",
      "Epoch 5/10\n",
      "6272/6300 [============================>.] - ETA: 0s - loss: 0.4214 - acc: 0.8036Epoch 00004: val_loss did not improve\n",
      "6300/6300 [==============================] - 89s - loss: 0.4220 - acc: 0.8030 - val_loss: 0.8366 - val_acc: 0.6686\n",
      "Epoch 6/10\n",
      "6272/6300 [============================>.] - ETA: 0s - loss: 0.3622 - acc: 0.8289Epoch 00005: val_loss did not improve\n",
      "6300/6300 [==============================] - 93s - loss: 0.3622 - acc: 0.8289 - val_loss: 0.9477 - val_acc: 0.6957\n",
      "Epoch 7/10\n",
      "6272/6300 [============================>.] - ETA: 0s - loss: 0.3213 - acc: 0.8482Epoch 00006: val_loss did not improve\n",
      "6300/6300 [==============================] - 86s - loss: 0.3210 - acc: 0.8484 - val_loss: 1.3140 - val_acc: 0.6400\n",
      "Epoch 8/10\n",
      "6272/6300 [============================>.] - ETA: 0s - loss: 0.2663 - acc: 0.8798Epoch 00007: val_loss did not improve\n",
      "6300/6300 [==============================] - 86s - loss: 0.2659 - acc: 0.8800 - val_loss: 1.5524 - val_acc: 0.6014\n",
      "Epoch 9/10\n",
      "6272/6300 [============================>.] - ETA: 0s - loss: 0.2196 - acc: 0.8986Epoch 00008: val_loss did not improve\n",
      "6300/6300 [==============================] - 84s - loss: 0.2199 - acc: 0.8983 - val_loss: 1.8478 - val_acc: 0.5929\n",
      "Epoch 10/10\n",
      "6272/6300 [============================>.] - ETA: 0s - loss: 0.1893 - acc: 0.9142Epoch 00009: val_loss did not improve\n",
      "6300/6300 [==============================] - 84s - loss: 0.1896 - acc: 0.9141 - val_loss: 1.9064 - val_acc: 0.6171\n",
      "Evaluation...\n",
      "3000/3000 [==============================] - 8s     \n",
      "Test loss/accuracy final model = 1.7597, 0.6330\n"
     ]
    }
   ],
   "source": [
    "# training the data and saving the model\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=('/home/ramscrux7757/SPARK/AI_SCIENCE/qa-lstm-attn-best.hdf5'),\n",
    "    verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit([Xqtrain, Xatrain], [Ytrain], batch_size=batch_size, \n",
    "                    nb_epoch=10, validation_split=0.1,callbacks=[checkpoint])\n",
    "\n",
    "print(\"Evaluation...\")\n",
    "loss, acc = model.evaluate([Xqtest, Xatest], [Ytest], batch_size=batch_size)\n",
    "print(\"Test loss/accuracy final model = %.4f, %.4f\" % (loss, acc))\n",
    "# save the model\n",
    "#model.save('/home/ramscrux7757/SPARK/AI_SCIENCE/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Summarizing the Accuracy\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.plot(history.history['acc'])\n",
    "#plt.plot(history.history['val_acc'])\n",
    "#plt.title('model accuracy')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.ylabel('accuracy')\n",
    "#plt.legend(['train','validation'], loc='upper left')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/lib/python2.7/site-packages/keras/engine/topology.py:1252: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 8s     \n",
      "Test loss/accuracy best model = 0.558684201399, 0.754000000318\n"
     ]
    }
   ],
   "source": [
    "# loading the model and evaluating the test data\n",
    "from keras.models import load_model\n",
    "svd_model = load_model('/home/ramscrux7757/SPARK/AI_SCIENCE/qa-lstm-attn-best.hdf5')\n",
    "# svd_model = load_model('/home/ramscrux7757/SPARK/AI_SCIENCE/model.h5')\n",
    "#svd_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "loss, acc = svd_model.evaluate([Xqtest, Xatest], [Ytest], batch_size=batch_size)\n",
    "print(\"Test loss/accuracy best model = {}, {}\".format(loss,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25655362,  0.74344635],\n",
       "       [ 0.25579777,  0.7442022 ],\n",
       "       [ 0.25800636,  0.74199367],\n",
       "       ..., \n",
       "       [ 0.25846583,  0.74153417],\n",
       "       [ 0.25667426,  0.74332577],\n",
       "       [ 0.25576738,  0.74423265]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_model.predict([Xqtest, Xatest], batch_size=batch_size)\n",
    "# these predictions are compared against the Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " ..., \n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(Ytest) # vectorized form of True/False (correct_ans_idx = ord(correct_ans) - ord('A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving the model as separate files\n",
    "from numpy import array\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# convert the architecture to 'json' or 'yaml' file\n",
    "architecture = model.to_json()\n",
    "with open('/home/ramscrux7757/SPARK/AI_SCIENCE/architecture.json','wt') as json_file:\n",
    "    json_file.write(architecture)\n",
    "\n",
    "# saving the weights as *.hdf5 file\n",
    "#model.save_weights('weights.h5')\n",
    "#model.save_weights('/home/ramscrux7757/SPARK/AI_SCIENCE/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "from keras.models import model_from_json\n",
    "json_file = open('/home/ramscrux7757/SPARK/AI_SCIENCE/architecture.json','rt')\n",
    "architecture = json_file.read()\n",
    "json_file.close()\n",
    "# create model from architecture\n",
    "model = model_from_json(architecture)\n",
    "\n",
    "# loading weights\n",
    "model = model.load_weights('/home/ramscrux7757/SPARK/AI_SCIENCE/weights.h5')\n",
    "\n",
    "# making predictions\n",
    "yhat = model.predict(X, verbose=0)\n",
    "yhat = model.predict_classes(X)\n",
    "yhat = model.predict_proba(X)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The next step takes the saved model (final one) and runs each question \n",
    "# in the test set and its four choices as a single batch, and predicts \n",
    "# the correct answer as the one which has the highest score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing the test set\n",
    "def vectorize_qapairs(qapairs, word2idx, seq_maxlen):\n",
    "    Xtq, Xta = [], []\n",
    "    for qapair in qapairs:\n",
    "        Xtq.append([word2idx[qword] for qword in qapair[0]])\n",
    "        Xta.append([word2idx[aword] for aword in qapair[1]])\n",
    "        #Y.append(np.array([1, 0]) if qapair[2] else np.array([0, 1]))\n",
    "    return (pad_sequences(Xtq, maxlen=seq_maxlen), \n",
    "            pad_sequences(Xta, maxlen=seq_maxlen))\n",
    "            #np.array(Y))\n",
    "\n",
    "# index encoded qapairs vectors\n",
    "Xtq, Xta = vectorize_qapairs(tqapairs, word2idx, seq_maxlen)\n",
    "#print(Xtq)\n",
    "#print(Xta)\n",
    "#print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32528, 100)\n",
      "(32528, 100)\n"
     ]
    }
   ],
   "source": [
    "print(Xtq.shape)\n",
    "print(Xta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Xtq[0/1/2/3] - question no: 1\n",
    "#Xta[0] - answer 'A'\n",
    "#Xta[1] - answer 'B'\n",
    "#Xta[2] - answer 'C'\n",
    "#Xta[3] - answer 'D'\n",
    "# in the answer's vectors, if a single word is the answer, we will have one non-zero element in the vector at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   7,\n",
       "       822, 376,  70,  20, 101, 334,  37,  17,  16], dtype=int32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,  334,   12,\n",
       "       1145], dtype=int32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xta[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   7,\n",
       "       822, 376,  70,  20, 101, 334,  37,  17,  16], dtype=int32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtq[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "       1749], dtype=int32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xta[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following prediction is for demonstration purpuses only\n",
    "# The accuracy is not better than random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1:\n",
      "probability of Answers: [array([ 1.67015743], dtype=float32), array([ 1.66981757], dtype=float32), array([ 1.67062938], dtype=float32), array([ 1.67023623], dtype=float32)]\n",
      "correct_answer_predicted: C\n",
      "\n",
      "Question 2:\n",
      "probability of Answers: [array([ 1.66981757], dtype=float32), array([ 1.67062938], dtype=float32), array([ 1.67023623], dtype=float32), array([ 1.66986775], dtype=float32)]\n",
      "correct_answer_predicted: B\n",
      "\n",
      "Question 3:\n",
      "probability of Answers: [array([ 1.67062938], dtype=float32), array([ 1.67023623], dtype=float32), array([ 1.66986775], dtype=float32), array([ 1.66985476], dtype=float32)]\n",
      "correct_answer_predicted: A\n",
      "\n",
      "Question 4:\n",
      "probability of Answers: [array([ 1.67023623], dtype=float32), array([ 1.66986775], dtype=float32), array([ 1.66985476], dtype=float32), array([ 1.66988158], dtype=float32)]\n",
      "correct_answer_predicted: A\n",
      "\n",
      "Question 5:\n",
      "probability of Answers: [array([ 1.66956103], dtype=float32), array([ 1.66944647], dtype=float32), array([ 1.66940343], dtype=float32), array([ 1.66924858], dtype=float32)]\n",
      "correct_answer_predicted: A\n",
      "\n",
      "Question 6:\n",
      "probability of Answers: [array([ 1.66944647], dtype=float32), array([ 1.66940343], dtype=float32), array([ 1.66924858], dtype=float32), array([ 1.66971922], dtype=float32)]\n",
      "correct_answer_predicted: D\n",
      "\n",
      "Question 7:\n",
      "probability of Answers: [array([ 1.66940343], dtype=float32), array([ 1.66924858], dtype=float32), array([ 1.66971922], dtype=float32), array([ 1.67046368], dtype=float32)]\n",
      "correct_answer_predicted: D\n",
      "\n",
      "Question 8:\n",
      "probability of Answers: [array([ 1.66924858], dtype=float32), array([ 1.66971922], dtype=float32), array([ 1.67046368], dtype=float32), array([ 1.66952753], dtype=float32)]\n",
      "correct_answer_predicted: C\n",
      "\n",
      "Question 9:\n",
      "probability of Answers: [array([ 1.66995776], dtype=float32), array([ 1.67095029], dtype=float32), array([ 1.6699127], dtype=float32), array([ 1.67083549], dtype=float32)]\n",
      "correct_answer_predicted: B\n",
      "\n",
      "Question 10:\n",
      "probability of Answers: [array([ 1.67095029], dtype=float32), array([ 1.6699127], dtype=float32), array([ 1.67083549], dtype=float32), array([ 1.66951609], dtype=float32)]\n",
      "correct_answer_predicted: A\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a question and the corresponding answer set is supplied \n",
    "#for i in range(Xtq.shape[0]):\n",
    "\n",
    "for i in range(10):\n",
    "    x1 = Xtq[i]\n",
    "    xq1 = np.array([x1]) # transposing the vector\n",
    "    probs_list = []\n",
    "    for j in range(i, i+4): \n",
    "        x2 = Xta[j]\n",
    "        xa1 = np.array([x2])\n",
    "\n",
    "        Y = svd_model.predict([xq1,xa1])\n",
    "\n",
    "# consider the difference b/w the positive and negative o/p as the score followed by normalization\n",
    "# gives the probabilities of all \n",
    "        probs = np.exp(1.0 - (Y[:, 1] - Y[:, 0]))\n",
    "        probs_list.append(probs)\n",
    "\n",
    "# the following should covert the numeric into the correct character\n",
    "    correct_answer = chr(ord('A') + np.argmax(probs_list))\n",
    "    \n",
    "#    print(Y.shape)\n",
    "#        print(Y)\n",
    "#print('---------------')\n",
    "#print(Y[:,0])\n",
    "#print('---------------')\n",
    "#print(Y[:,1])\n",
    "#print('----------------')\n",
    "#print(len(probs))\n",
    "#        print(probs)\n",
    "#print('----------------')\n",
    "#    print(np.argmax(probs))\n",
    "#print('----------------')\n",
    "    print('Question {}:'.format(i+1))\n",
    "    print('probability of Answers: {}'.format(probs_list))\n",
    "    print('correct_answer_predicted: {}'.format(correct_answer))\n",
    "    print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
