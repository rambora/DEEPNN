{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "....\n",
    "....\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X:X_batch, y:y_batch})\n",
    "            \n",
    "        acc_train = accuracy.eval(feed_dict = {X: X_batch, y: y_batch})\n",
    "        acc_test  = accuracy.eval(feed_dict = {X: mnist.test.images, y: mnist.test.labels})\n",
    "        print(epoch, 'Train_accurayc:', acc_train, 'Test_accuracy:', acc_test)\n",
    "    save_path = saver.save(sess, '/home/ramscrux7757/SPARK/MNIST/my_mode_final.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using the saved_chkpt\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, '/home/ramscrux7757/SPARK/MNIST/my_mode_final.ckpt')\n",
    "    #X_test = [.....]\n",
    "    Z = logits.eval(feed_dict={X: mnist.test.images})\n",
    "    y_pred = np.argmax(Z, axis=1)\n",
    "    print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "def define_model(vocab_size, max_length):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
    "    model.add(Conv1D(filters=32, kernel_size=8, activation='relu')) \n",
    "    # kernel_size - is the number of words to consider as the convolutional is passed across the \n",
    "    # input text document\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10,activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile the network\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = define_model(vocab_size, max_length)\n",
    "model.fit(Xtrain2, ytrain,epochs=50,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('/home/ramscrux7757/SPARK/SENT_ANALS/sent_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "from keras.models import load_model\n",
    "model = load_model('/home/ramscrux7757/SPARK/SENT_ANALS/sent_model.h5')\n",
    "# evaluate the model on the test data\n",
    "_, acc = model.evaluate(Xtest2, ytest, verbose=0)\n",
    "print('Test Accuracy: {}'.format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# option 2: (this is better as it saves the better one !!!)\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=('/home/ramscrux7757/SPARK/AI_SCIENCE/qa-lstm-attn-best.hdf5'),\n",
    "    verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit([Xqtrain, Xatrain], [Ytrain], batch_size=batch_size, \n",
    "                    nb_epoch=10, validation_split=0.1,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading the model and evaluating the test data\n",
    "from keras.models import load_model\n",
    "svd_model = load_model('/home/ramscrux7757/SPARK/AI_SCIENCE/qa-lstm-attn-best.hdf5')\n",
    "loss, acc = svd_model.evaluate([Xqtest, Xatest], [Ytest], batch_size=batch_size)\n",
    "svd_model.predict([Xqtest, Xatest], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# option 3:\n",
    "# saving the model as separate files\n",
    "from numpy import array\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# convert the architecture to 'json' or 'yaml' file\n",
    "architecture = model.to_json()\n",
    "with open('/home/ramscrux7757/SPARK/AI_SCIENCE/architecture.json','wt') as json_file:\n",
    "    json_file.write(architecture)\n",
    "\n",
    "# saving the weights as *.hdf5 file\n",
    "#model.save_weights('weights.h5')\n",
    "#model.save_weights('/home/ramscrux7757/SPARK/AI_SCIENCE/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "from keras.models import model_from_json\n",
    "json_file = open('/home/ramscrux7757/SPARK/AI_SCIENCE/architecture.json','rt')\n",
    "architecture = json_file.read()\n",
    "json_file.close()\n",
    "# create model from architecture\n",
    "model = model_from_json(architecture)\n",
    "\n",
    "# loading weights\n",
    "model = model.load_weights('/home/ramscrux7757/SPARK/AI_SCIENCE/weights.h5')\n",
    "\n",
    "# making predictions\n",
    "yhat = model.predict(X, verbose=0)\n",
    "yhat = model.predict_classes(X)\n",
    "yhat = model.predict_proba(X)\n",
    "print(yhat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
