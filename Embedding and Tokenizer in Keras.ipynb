{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following are various methods within Tokenizer class\n",
    "\n",
    "# tokenizer = Tokenizer()\n",
    "# tokenizer.fit_on_texts([])\n",
    "# tokenizer.texts_to_matrix([])\n",
    "# tokenizer.texts_to_sequences([])\n",
    "# tokenizer.word_index\n",
    "# tokenizer.word_counts\n",
    "# tokenizer.document_count\n",
    "# tokenizer.lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_words = 3 # maximum number of words to workwith\n",
    "tokenizer = Tokenizer(nb_words=nb_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'beautiful': 10, 'this': 15, 'life': 9, 'and': 16, 'august': 11, 'things': 18, 'september': 7, 'sun': 4, 'is': 1, 'june': 6, 'grey': 8, 'like': 13, 'i': 12, 'other': 17, 'in': 2, 'it': 14, 'the': 3, 'shining': 5}\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "tokenizer.fit_on_texts([\"The sun is shining in June!\",\"September is grey.\",\"Life is beautiful in August.\",\n",
    "                        \"I like it\",\"This and other things?\"])\n",
    "# the word index can be found using 'word_index'\n",
    "print(tokenizer.word_index)\n",
    "# the special characters (such as !, ? etc) will automatically taken care\n",
    "# but numerics will not be taken care yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([\"June is beautiful and I like it!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'beautiful': 10, 'this': 15, 'life': 9, 'and': 16, 'august': 11, 'things': 18, 'september': 7, 'sun': 4, 'is': 1, 'june': 6, 'grey': 8, 'like': 13, 'i': 12, 'other': 17, 'in': 2, 'it': 14, 'the': 3, 'shining': 5}\n",
      "[[ 0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  0.\n",
      "   0.]]\n",
      "[[6, 1, 10, 16, 12, 13, 14]]\n"
     ]
    }
   ],
   "source": [
    "# a parameter less constructor behaves betterly\n",
    "tokenizer = Tokenizer()\n",
    "texts = [\"The sun is shining in June!\",\"September is grey.\",\"Life is beautiful in August.\",\"I like it\",\"This and other things?\"]\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "print(tokenizer.word_index)\n",
    "print(tokenizer.texts_to_matrix(['June is beautiful and I like it!'])) # vector size based on the vocabulary size\n",
    "# useful for statistical based modeling (tf-idf etc)\n",
    "print(tokenizer.texts_to_sequences([\"June is beautiful and I like it!\"])) # vector size based on the length of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('the', 1), ('sun', 1), ('is', 3), ('shining', 1), ('in', 2), ('june', 1), ('september', 1), ('grey', 1), ('life', 1), ('beautiful', 1), ('august', 1), ('i', 1), ('like', 1), ('it', 1), ('this', 1), ('and', 1), ('other', 1), ('things', 1)])\n"
     ]
    }
   ],
   "source": [
    "# word counts\n",
    "print(tokenizer.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.document_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's assume that the following learns a word being represented as 'y' and see if the network can predict the sameword or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The sun is shining in June!', 'September is grey.', 'Life is beautiful in August.', 'I like it', 'This and other things?']\n",
      "[[ 0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.]\n",
      " [ 0.  1.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.\n",
      "   0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.\n",
      "   1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/lib/python2.7/site-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f26deb042d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "print(texts)\n",
    "X = tokenizer.texts_to_matrix(texts)\n",
    "y = [1,0,0,0,0]\n",
    "print(X)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=vocab_size))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    " \n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "model.fit(X, y=y, batch_size=32, nb_epoch=20, verbose=0, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import np as np\n",
    "np.round(model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 7, 2)              4         \n",
      "=================================================================\n",
      "Total params: 4\n",
      "Trainable params: 4\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(2, 2, input_length=7))\n",
    "# size of the vocabulary (0,1 here), size of the vector space in which the input is mapped\n",
    "# input length\n",
    "model.compile('rmsprop', 'mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00923343,  0.03239873],\n",
       "        [ 0.01686737,  0.03767406],\n",
       "        [ 0.00923343,  0.03239873],\n",
       "        [ 0.01686737,  0.03767406],\n",
       "        [ 0.01686737,  0.03767406],\n",
       "        [ 0.00923343,  0.03239873],\n",
       "        [ 0.00923343,  0.03239873]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([[0,1,0,1,1,0,0]]))\n",
    "# we are mapping every binary element (0 or 1) into a 2D space\n",
    "# this would produce a non-sparse/Dense 7x2 map matrix\n",
    "# here, each element is represented as a vector of 2 elements\n",
    "# clearly, all 0's are represented by [0.00923343,  0.03239873] and\n",
    "# all '1's are represented by [0.01686737,  0.03767406]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding class does indeed map discrete labels (words) into a continuous vector space. \n",
    "# This embedding does not in any way take the semantic similarity of the words into account. Hence embedding in keras and word2vec (of gensim) are completely different ways of expressing the labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.layers[0].get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "         1.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  1.,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 19, 10)            30        \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 190)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 191       \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f26cd187e90>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(3, 10, input_length= X.shape[1] ))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "model.summary()\n",
    "model.fit(X, y=y, batch_size=32, nb_epoch=700, verbose=0, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00],\n",
       "       [  9.82496928e-08],\n",
       "       [  9.64378088e-08],\n",
       "       [  9.14945897e-09],\n",
       "       [  9.92534161e-01]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)\n",
    "# it perfectly predicts the word as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f26afdaeb10>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10))\n",
    "model.add(LSTM(5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "model.fit(X, y=y,  nb_epoch=500, verbose=0, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.93342745],\n",
       "       [ 0.01597509],\n",
       "       [ 0.01614392],\n",
       "       [ 0.01633371],\n",
       "       [ 0.02689865]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "\n",
    "embeddings_index = dict()\n",
    "with open('/home/ramscrux7757/SPARK/glove/glove.6B.50d.txt') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "        \n",
    "print('Loaded {} word vectors'.format(len(embeddings_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "glove_data = '/Users/Swa/Desktop/AIML/Glove/glove.6B.50d.txt'\n",
    "f = open(glove_data)\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    value = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = value\n",
    "f.close()\n",
    "\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_dimension = 50\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'beautiful': 10, 'this': 15, 'life': 9, 'and': 16, 'august': 11, 'things': 18, 'september': 7, 'sun': 4, 'is': 1, 'june': 6, 'grey': 8, 'like': 13, 'i': 12, 'other': 17, 'in': 2, 'it': 14, 'the': 3, 'shining': 5}\n"
     ]
    }
   ],
   "source": [
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 50)\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  6.18499994e-01   6.42539978e-01  -4.65519994e-01   3.75699997e-01\n",
      "    7.48380005e-01   5.37389994e-01   2.22390005e-03  -6.05769992e-01\n",
      "    2.64079988e-01   1.17030002e-01   4.37220007e-01   2.00920001e-01\n",
      "   -5.78589998e-02  -3.45889986e-01   2.16639996e-01   5.85730016e-01\n",
      "    5.39189994e-01   6.94899976e-01  -1.56179994e-01   5.58300018e-02\n",
      "   -6.05149984e-01  -2.89970011e-01  -2.55939998e-02   5.55930018e-01\n",
      "    2.53560007e-01  -1.96120000e+00  -5.13809979e-01   6.90959990e-01\n",
      "    6.62460029e-02  -5.42239994e-02   3.78710008e+00  -7.74030030e-01\n",
      "   -1.26890004e-01  -5.14649987e-01   6.67050034e-02  -3.29329997e-01\n",
      "    1.34829998e-01   1.90490007e-01   1.38119996e-01  -2.15030000e-01\n",
      "   -1.65730007e-02   3.12000006e-01  -3.31889987e-01  -2.60010008e-02\n",
      "   -3.82030010e-01   1.94030002e-01  -1.24660000e-01  -2.75570005e-01\n",
      "    3.08990002e-01   4.84970003e-01]\n",
      " [  3.30419987e-01   2.49950007e-01  -6.08739972e-01   1.09229997e-01\n",
      "    3.63719985e-02   1.50999993e-01  -5.50830007e-01  -7.42390007e-02\n",
      "   -9.23070014e-02  -3.28209996e-01   9.59800035e-02  -8.22690010e-01\n",
      "   -3.67170006e-01  -6.70090020e-01   4.29089993e-01   1.64960008e-02\n",
      "   -2.35730007e-01   1.28639996e-01  -1.09529996e+00   4.33340013e-01\n",
      "    5.70670009e-01  -1.03600003e-01   2.04219997e-01   7.83080012e-02\n",
      "   -4.27949995e-01  -1.79840004e+00  -2.78649986e-01   1.19539998e-01\n",
      "   -1.26890004e-01   3.17439996e-02   3.86310005e+00  -1.77860007e-01\n",
      "   -8.24339986e-02  -6.26980007e-01   2.64970005e-01  -5.71850017e-02\n",
      "   -7.35210031e-02   4.61030006e-01   3.08620006e-01   1.24980003e-01\n",
      "   -4.86090004e-01  -8.02719966e-03   3.11840009e-02  -3.65759999e-01\n",
      "   -4.26990002e-01   4.21640009e-01  -1.16659999e-01  -5.07030010e-01\n",
      "   -2.72729993e-02  -5.32850027e-01]\n",
      " [  4.18000013e-01   2.49679998e-01  -4.12420005e-01   1.21699996e-01\n",
      "    3.45270008e-01  -4.44569997e-02  -4.96879995e-01  -1.78619996e-01\n",
      "   -6.60229998e-04  -6.56599998e-01   2.78430015e-01  -1.47670001e-01\n",
      "   -5.56770027e-01   1.46579996e-01  -9.50950012e-03   1.16579998e-02\n",
      "    1.02040000e-01  -1.27920002e-01  -8.44299972e-01  -1.21809997e-01\n",
      "   -1.68009996e-02  -3.32789987e-01  -1.55200005e-01  -2.31309995e-01\n",
      "   -1.91809997e-01  -1.88230002e+00  -7.67459989e-01   9.90509987e-02\n",
      "   -4.21249986e-01  -1.95260003e-01   4.00710011e+00  -1.85939997e-01\n",
      "   -5.22870004e-01  -3.16810012e-01   5.92130003e-04   7.44489999e-03\n",
      "    1.77780002e-01  -1.58969998e-01   1.20409997e-02  -5.42230010e-02\n",
      "   -2.98709989e-01  -1.57490000e-01  -3.47579986e-01  -4.56370004e-02\n",
      "   -4.42510009e-01   1.87849998e-01   2.78489990e-03  -1.84110001e-01\n",
      "   -1.15139998e-01  -7.85809994e-01]\n",
      " [ -3.72330010e-01   1.66799998e+00   6.56159997e-01   1.28429997e+00\n",
      "   -7.09460005e-02  -1.61530006e+00  -2.86540002e-01  -6.73169971e-01\n",
      "   -4.98869985e-01   1.05310000e-01   1.80920005e-01   4.04949993e-01\n",
      "    5.23880005e-01   2.85400003e-01  -2.50759989e-01   7.51489997e-01\n",
      "   -1.21529996e+00   5.34380004e-02  -1.06490004e+00   3.71249989e-02\n",
      "   -2.28330001e-01   3.03979993e-01   1.26880002e+00  -8.54939997e-01\n",
      "    4.93299991e-01  -9.24629986e-01  -1.46500006e-01   5.33330023e-01\n",
      "    2.06609994e-01  -5.45700006e-02   2.61929989e+00  -1.14239998e-01\n",
      "   -3.00390005e-01  -1.83840003e-03  -7.76400030e-01  -5.82289994e-01\n",
      "   -4.18170005e-01  -4.03710008e-02   4.18830007e-01  -2.39309996e-01\n",
      "    2.12500006e-01  -1.73150003e-01  -3.13510001e-01   3.60399991e-01\n",
      "    7.99809992e-01  -1.71440005e-01   1.92949995e-01  -1.61960006e+00\n",
      "    3.41349989e-01  -1.77259997e-01]\n",
      " [  2.06689999e-01   4.55029994e-01   6.20710015e-01   1.13109998e-01\n",
      "    6.27349973e-01  -9.32900012e-01   5.54979980e-01  -5.75299978e-01\n",
      "   -1.41939998e-01   7.20189989e-01  -1.32630002e-02  -1.85829997e-01\n",
      "   -5.23519993e-01   5.55809975e-01  -7.55550027e-01  -2.79269993e-01\n",
      "   -1.75579995e-01   7.03840017e-01  -5.05029976e-01  -2.31150001e-01\n",
      "   -1.20840001e+00   7.38709986e-01   6.46009982e-01  -8.55949998e-01\n",
      "   -2.40490004e-01  -5.50599992e-01  -1.09500003e+00   8.21780026e-01\n",
      "    6.28549993e-01   3.63520011e-02   1.07560003e+00  -2.65230000e-01\n",
      "   -7.41919994e-01  -3.23630005e-01  -1.16240002e-01   1.09490000e-01\n",
      "   -9.74990010e-01  -7.78280020e-01  -8.73170018e-01  -4.57470000e-01\n",
      "   -5.79299986e-01   6.81509972e-02  -3.74940008e-01  -7.23420024e-01\n",
      "    2.76300013e-01  -4.52419996e-01   2.63720006e-01  -1.25409997e+00\n",
      "   -3.92980009e-01  -1.16639996e+00]\n",
      " [ -3.88749987e-02   1.76129997e-01  -1.60380006e-02  -6.40660003e-02\n",
      "   -2.09130004e-01   4.98250015e-02  -1.09290004e+00   4.53170016e-02\n",
      "   -6.20329976e-01  -7.47900009e-01   3.32309991e-01  -7.05020010e-01\n",
      "   -3.88429999e-01  -4.74480003e-01   1.44959998e+00   3.08389992e-01\n",
      "   -1.31490004e+00  -5.61689973e-01  -1.65950000e+00   8.58479977e-01\n",
      "    1.30560005e+00  -3.56660008e-01   8.13950002e-01  -4.82609987e-01\n",
      "   -7.72759974e-01  -1.16139996e+00   6.04809999e-01  -4.11179990e-01\n",
      "   -7.61250034e-02   9.35329974e-01   2.87759995e+00  -2.88859993e-01\n",
      "   -1.04890001e+00  -3.02940011e-01   3.07900012e-01  -9.69060004e-01\n",
      "    7.41140008e-01   7.06619993e-02   2.41359994e-02  -4.75670010e-01\n",
      "   -7.37349987e-01  -5.49929976e-01  -1.32320002e-01  -1.38610005e+00\n",
      "   -3.80719990e-01   1.44140005e-01  -1.65319994e-01  -7.34200001e-01\n",
      "   -1.49459997e-02   1.56340003e-01]\n",
      " [  3.85430008e-02  -9.63149965e-02   4.22339998e-02  -3.09450001e-01\n",
      "   -2.37629995e-01  -2.50950009e-02  -1.11039996e+00   2.88520008e-02\n",
      "   -5.17989993e-01  -6.45560026e-01   4.81519997e-01  -5.56529999e-01\n",
      "   -4.04309988e-01  -5.88490009e-01   1.19360006e+00   5.06730005e-02\n",
      "   -1.27600002e+00  -4.79790002e-01  -1.67789996e+00   9.41890001e-01\n",
      "    1.37189996e+00  -3.56449991e-01   7.20709980e-01  -5.09130001e-01\n",
      "   -6.04700029e-01  -1.16919994e+00   4.78509992e-01  -3.89990002e-01\n",
      "   -7.03700036e-02   1.06780005e+00   2.85610008e+00  -4.16929990e-01\n",
      "   -6.33260012e-01  -4.65849996e-01   1.34580001e-01  -6.61989987e-01\n",
      "    6.74080014e-01  -1.48430001e-02  -1.43169999e-01  -4.16590005e-01\n",
      "   -6.76410019e-01  -5.35340011e-01  -3.47970009e-01  -1.44630003e+00\n",
      "   -4.67319995e-01   7.60819986e-02  -2.43100002e-01  -6.33899987e-01\n",
      "    6.08160011e-02   9.21930000e-02]\n",
      " [ -3.64520013e-01   4.19690013e-01  -1.00199997e+00  -5.09790003e-01\n",
      "    9.36489999e-01   5.62240005e-01  -7.44840026e-01  -8.41840029e-01\n",
      "    1.87659994e-01  -1.35440004e+00   3.08829993e-01   7.22559988e-01\n",
      "    4.68270004e-01   3.09760004e-01  -8.11089993e-01   2.53459990e-01\n",
      "   -8.19299966e-02  -6.14419997e-01  -1.23360002e+00  -6.89490020e-01\n",
      "   -6.76010013e-01  -1.25860006e-01   1.00940001e+00  -3.82789999e-01\n",
      "   -1.19719994e+00  -2.36340001e-01  -8.79920006e-01   1.17750001e+00\n",
      "   -1.85360000e-01  -1.26890004e-01   1.19519997e+00  -1.55330002e-01\n",
      "    4.59239990e-01  -7.08419979e-01   3.90610009e-01   2.55939990e-01\n",
      "   -3.95210013e-02  -4.77420002e-01  -1.66930005e-01  -1.25950003e+00\n",
      "   -9.77730006e-02   2.71140009e-01  -2.04410002e-01  -6.27129972e-01\n",
      "    2.51309991e-01  -4.36990000e-02   2.83840001e-02  -1.57410002e+00\n",
      "    4.26030010e-01   1.44909993e-01]\n",
      " [  5.14909983e-01   8.88059974e-01  -7.19060004e-01  -5.74800014e-01\n",
      "    8.56549978e-01   5.24739981e-01  -3.17880005e-01  -2.01680005e-01\n",
      "    1.79360002e-01   5.19990027e-01  -1.15270004e-01   5.92960000e-01\n",
      "   -3.46799999e-01   5.25679998e-02   8.71529996e-01  -3.65820006e-02\n",
      "   -5.60569987e-02   8.51600021e-02   3.62490006e-02   2.34029993e-01\n",
      "    7.31749982e-02   1.13940001e+00  -1.79210007e-01  -3.42449993e-02\n",
      "    6.99769974e-01  -1.65160000e+00  -1.10599995e+00  -4.41450000e-01\n",
      "    7.70420015e-01   2.39629999e-01   3.18230009e+00  -2.04510000e-02\n",
      "   -5.61169982e-02  -6.99180007e-01  -1.95429996e-01   1.94920003e-01\n",
      "   -3.64030004e-01   5.31960018e-02   2.62250006e-01  -2.90540010e-01\n",
      "   -6.48829997e-01  -5.78459986e-02   2.16460004e-01   4.02370006e-01\n",
      "   -1.41299993e-01  -1.54529996e-02  -1.19879998e-01  -9.98369992e-01\n",
      "   -6.63279966e-02   1.31180003e-01]\n",
      " [  5.46230018e-01   1.20420003e+00  -1.12880003e+00  -1.32499993e-01\n",
      "    9.55290020e-01   4.05239984e-02  -4.78630006e-01  -3.39700013e-01\n",
      "   -2.80559987e-01   7.17610002e-01  -5.36909997e-01  -4.56980010e-03\n",
      "    7.32169986e-01   1.21009998e-01   2.80930012e-01  -8.80969986e-02\n",
      "    5.97329974e-01   5.52640021e-01   5.66460006e-02  -5.02470016e-01\n",
      "   -6.32040024e-01   1.14390004e+00  -3.10530007e-01   1.26300007e-01\n",
      "    1.31550002e+00  -5.24439991e-01  -1.50409997e+00   1.15799999e+00\n",
      "    6.87950015e-01  -8.50510001e-01   2.32360005e+00  -4.17890012e-01\n",
      "    4.45190012e-01  -1.92159992e-02   2.89689988e-01   5.32580018e-01\n",
      "   -2.30080001e-02   5.89579999e-01  -7.23969996e-01  -8.52159977e-01\n",
      "   -1.77609995e-01   1.44319996e-01   4.06580001e-01  -5.20030022e-01\n",
      "    9.08100009e-02   8.29610005e-02  -2.19749995e-02  -1.62140000e+00\n",
      "    3.45789999e-01  -1.09190000e-02]\n",
      " [ -3.10769994e-02  -4.40439992e-02   3.56639996e-02  -3.56830001e-01\n",
      "   -2.57149994e-01   5.60799986e-02  -1.22189999e+00   2.43090004e-01\n",
      "   -5.05779982e-01  -6.74329996e-01   5.94359994e-01  -5.89550018e-01\n",
      "   -3.81900012e-01  -7.06960022e-01   1.28489995e+00   9.18620005e-02\n",
      "   -1.14859998e+00  -4.06699985e-01  -1.76919997e+00   8.95250022e-01\n",
      "    1.34200001e+00  -4.04810011e-01   7.25340009e-01  -4.60429996e-01\n",
      "   -5.61299980e-01  -1.14100003e+00   4.68309999e-01  -4.95460004e-01\n",
      "   -1.66170001e-02   1.04359996e+00   2.68120003e+00  -4.56319988e-01\n",
      "   -7.56049991e-01  -4.15719986e-01   1.54949993e-01  -5.31080008e-01\n",
      "    6.27499998e-01   1.19300000e-01   1.74940005e-02  -2.85589993e-01\n",
      "   -4.94509995e-01  -4.52899992e-01  -2.50959992e-01  -1.55470002e+00\n",
      "   -4.51319993e-01  -3.15750018e-02  -1.83129996e-01  -7.58710027e-01\n",
      "   -5.26649989e-02   3.78380008e-02]\n",
      " [  1.18910000e-01   1.52549997e-01  -8.20730031e-02  -7.41439998e-01\n",
      "    7.59169996e-01  -4.83280003e-01  -3.10090005e-01   5.14760017e-01\n",
      "   -9.87079978e-01   6.17570011e-04  -1.50429994e-01   8.37700009e-01\n",
      "   -1.07969999e+00  -5.14599979e-01   1.31879997e+00   6.20069981e-01\n",
      "    1.37789994e-01   4.71080005e-01  -7.28740022e-02  -7.26750016e-01\n",
      "   -7.41159976e-01   7.52629995e-01   8.81799996e-01   2.95610011e-01\n",
      "    1.35479999e+00  -2.57010007e+00  -1.35230005e+00   4.58799988e-01\n",
      "    1.00680006e+00  -1.18560004e+00   3.47370005e+00   7.78980017e-01\n",
      "   -7.29290009e-01   2.51020014e-01  -2.61559993e-01  -3.46839994e-01\n",
      "    5.58409989e-01   7.50980020e-01   4.98299986e-01  -2.68229991e-01\n",
      "   -2.74430006e-03  -1.82980001e-02  -2.80959994e-01   5.53179979e-01\n",
      "    3.77059989e-02   1.85550004e-01  -1.50250003e-01  -5.75119972e-01\n",
      "   -2.66710013e-01   9.21209991e-01]\n",
      " [  3.68079990e-01   2.08340004e-01  -2.23189995e-01   4.62829992e-02\n",
      "    2.00979993e-01   2.75150001e-01  -7.71269977e-01  -7.68040001e-01\n",
      "   -3.48610014e-01   5.06200016e-01  -2.44010001e-01   7.17750013e-01\n",
      "   -3.33480000e-01   3.75539988e-01   4.47560012e-01   3.66979986e-01\n",
      "    4.35330003e-01   4.75699991e-01  -5.61130010e-02  -9.35310006e-01\n",
      "   -2.75909990e-01   3.16100001e-01   2.21159995e-01   3.63040000e-01\n",
      "    1.07570000e-01  -1.76380002e+00  -1.26240003e+00   3.02839994e-01\n",
      "    5.62860012e-01  -1.02139997e+00   3.23530006e+00   4.84829992e-01\n",
      "    2.79530007e-02   3.60819995e-02  -7.85539970e-02   1.87610000e-01\n",
      "   -5.25730014e-01   3.72000001e-02   2.75790006e-01  -7.73599967e-02\n",
      "   -2.79549986e-01   7.97519982e-01   1.60279998e-03   4.54789996e-01\n",
      "    8.83819997e-01   4.38930005e-01  -1.92629993e-01  -6.72360003e-01\n",
      "   -3.97089988e-01   2.51830012e-01]\n",
      " [  6.11829996e-01  -2.20719993e-01  -1.08980000e-01  -5.29670008e-02\n",
      "    5.08040011e-01   3.46839994e-01  -3.35579991e-01  -1.91520005e-01\n",
      "   -3.58650014e-02   1.05099998e-01   7.93500021e-02   2.44900003e-01\n",
      "   -4.37299997e-01  -3.33440006e-01   5.74790001e-01   6.90519989e-01\n",
      "    2.97129989e-01   9.06689987e-02  -5.49920022e-01  -4.61760014e-01\n",
      "    1.01130001e-01  -2.02399995e-02   2.84790009e-01   4.35120016e-02\n",
      "    4.57349986e-01  -2.04660010e+00  -5.80839992e-01   6.17969990e-01\n",
      "    6.51799977e-01  -5.82629979e-01   4.07859993e+00  -2.54200011e-01\n",
      "   -1.46489993e-01  -3.43210012e-01  -2.54370004e-01  -4.46770012e-01\n",
      "    1.26570001e-01   2.81340003e-01   1.33310005e-01  -3.69740009e-01\n",
      "    5.00589982e-02  -1.00579999e-01  -1.79069992e-02   1.11419998e-01\n",
      "   -7.17980027e-01   4.90999997e-01  -9.99739990e-02  -4.36879992e-02\n",
      "   -9.79219973e-02   1.68060005e-01]\n",
      " [  5.30740023e-01   4.01169986e-01  -4.07849997e-01   1.54440001e-01\n",
      "    4.77820009e-01   2.07540005e-01  -2.69510001e-01  -3.40229988e-01\n",
      "   -1.08790003e-01   1.05630003e-01  -1.02890000e-01   1.08489998e-01\n",
      "   -4.96809989e-01  -2.51280010e-01   8.40250015e-01   3.89490008e-01\n",
      "    3.22840005e-01  -2.27970004e-01  -4.43419993e-01  -3.16489995e-01\n",
      "   -1.24059997e-01  -2.81699985e-01   1.94670007e-01   5.55129983e-02\n",
      "    5.67049980e-01  -1.74189997e+00  -9.11450028e-01   2.70359993e-01\n",
      "    4.19270009e-01   2.02789996e-02   4.04050016e+00  -2.49430001e-01\n",
      "   -2.04160005e-01  -6.27619982e-01  -5.47830015e-02  -2.68830001e-01\n",
      "    1.84440002e-01   1.82040006e-01  -2.35359997e-01  -1.61550000e-01\n",
      "   -2.76549995e-01   3.55059989e-02  -3.82110000e-01  -7.51340005e-04\n",
      "   -2.48219997e-01   2.81639993e-01   1.28189996e-01   2.87620008e-01\n",
      "    1.44400001e-01   2.36110002e-01]\n",
      " [  2.68180013e-01   1.43460006e-01  -2.78770000e-01   1.62569992e-02\n",
      "    1.13839999e-01   6.99230015e-01  -5.13320029e-01  -4.73679990e-01\n",
      "   -3.30749989e-01  -1.38339996e-01   2.70200014e-01   3.09379995e-01\n",
      "   -4.50120002e-01  -4.12699997e-01  -9.93200019e-02   3.80849987e-02\n",
      "    2.97490004e-02   1.00759998e-01  -2.50580013e-01  -5.18180013e-01\n",
      "    3.45580012e-01   4.49220002e-01   4.87910002e-01  -8.08660015e-02\n",
      "   -1.01209998e-01  -1.37769997e+00  -1.08659998e-01  -2.32010007e-01\n",
      "    1.28389997e-02  -4.65079993e-01   3.84629989e+00   3.13620001e-01\n",
      "    1.36429995e-01  -5.22440016e-01   3.30199987e-01   3.37069988e-01\n",
      "   -3.56009990e-01   3.24310005e-01   1.20410003e-01   3.51200014e-01\n",
      "   -6.90430030e-02   3.68849993e-01   2.51679987e-01  -2.45169997e-01\n",
      "    2.53809988e-01   1.36700004e-01  -3.11780006e-01  -6.32099986e-01\n",
      "   -2.50279993e-01  -3.80970001e-01]\n",
      " [  6.47560000e-01   1.59999996e-01   2.91910004e-02   3.51179987e-01\n",
      "    8.91190022e-02   6.11150026e-01  -6.63619995e-01  -5.17239988e-01\n",
      "   -4.65209991e-01  -8.84499997e-02   5.02000004e-02   2.63289988e-01\n",
      "    1.24070004e-01   4.38320003e-02   1.72830001e-01   1.31700002e-02\n",
      "    1.41680002e-01  -1.58270001e-01  -1.04269996e-01  -9.30700004e-01\n",
      "    2.16460004e-01  -1.07529998e-01   6.20869994e-01   3.67610008e-01\n",
      "   -4.81440008e-01  -1.27999997e+00  -5.51519990e-01  -7.20229983e-01\n",
      "   -1.70969993e-01  -4.79930013e-01   4.01650000e+00   4.70539987e-01\n",
      "    9.36139971e-02  -8.63409996e-01   5.08809984e-01   3.33530009e-01\n",
      "   -3.59620005e-01  -1.66480005e-01  -3.18030000e-01   4.90029991e-01\n",
      "   -3.66970003e-01   3.20510000e-01   7.09320009e-01   6.28780007e-01\n",
      "    7.01279998e-01   1.30199999e-01  -7.37689972e-01   1.03249997e-01\n",
      "   -3.09639990e-01  -4.42129999e-01]\n",
      " [  2.26779997e-01  -1.46270007e-01  -3.40420008e-01  -3.94560009e-01\n",
      "    7.21939981e-01  -1.45480007e-01  -4.02669996e-01  -1.64700001e-01\n",
      "   -6.29270017e-01   3.54510009e-01  -5.78270018e-01   8.34879994e-01\n",
      "   -8.99820030e-01  -3.26690003e-02   1.14549994e+00   5.93240023e-01\n",
      "    5.06420016e-01  -8.29510018e-02   4.92069989e-01  -1.11689997e+00\n",
      "   -6.38329983e-02   5.82700014e-01   6.04610026e-01   1.91440001e-01\n",
      "    1.12559998e+00  -1.51859999e+00  -1.15579998e+00   3.68840009e-01\n",
      "    1.50090003e+00  -9.55699980e-01   3.21620011e+00   7.13360012e-01\n",
      "   -1.76530004e-01  -6.41640007e-01  -1.85629994e-01   1.99919999e-01\n",
      "   -3.40189993e-01   5.35149992e-01   1.38620004e-01  -9.92629975e-02\n",
      "   -5.90260029e-01   1.00210004e-01   1.77709997e-01   7.16449976e-01\n",
      "    1.97229996e-01   3.92839998e-01   2.42149994e-01   8.20519999e-02\n",
      "    4.52280007e-02   6.33159995e-01]]\n"
     ]
    }
   ],
   "source": [
    "# create a weeight matrix for words in training docs\n",
    "# the embedding matrix is a (doc_size x embedded space) dimension matrix\n",
    "# every doc is a vector of 100 elements (in this case)\n",
    "vocab_size = len(word_index)+1\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dimension))\n",
    "#print(embedding_matrix)\n",
    "for word, i in word_index.items():\n",
    "    #print(word,i)\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if  embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "print(embedding_matrix.shape)\n",
    "print(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dimension))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector[:embedding_dimension]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 50)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "                            embedding_matrix.shape[1],\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = tokenizer.texts_to_sequences(texts)\n",
    "X = pad_sequences(X, maxlen=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  3,  4,  1,  5,  2,  6],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  7,  1,  8],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  9,  1, 10,  2, 11],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 12, 13, 14],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 15, 16, 17, 18]], dtype=int32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f26afb26ed0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.layers[0].trainable=False\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "model.fit(X, y=y, batch_size=20, nb_epoch=700, verbose=0, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00],\n",
       "       [  9.72407150e-08],\n",
       "       [  9.93706735e-08],\n",
       "       [  3.49633176e-08],\n",
       "       [  1.48684252e-03]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
